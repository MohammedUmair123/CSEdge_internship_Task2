{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDrgM5Hl-o4X"
      },
      "outputs": [],
      "source": [
        "#Task-2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import string  # To process standard python strings\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Download required NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample corpus for the chatbot to learn from\n",
        "corpus = \"\"\"Hello! How can I assist you today?\n",
        "            I can help you with your queries.\n",
        "            Please feel free to ask any questions.\n",
        "            Thank you for using our service.\n",
        "            Goodbye!\"\"\"\n",
        "\n",
        "# Tokenize the corpus into sentences\n",
        "sentence_tokens = nltk.sent_tokenize(corpus)\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize tokens\n",
        "def LemTokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "# Function to normalize text\n",
        "def Normalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(str.maketrans('', '', string.punctuation))))\n",
        "\n",
        "# Greeting responses\n",
        "greeting_inputs = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
        "greeting_responses = [\"Hi\", \"Hey\", \"Hello\", \"Greetings! How can I assist you today?\"]\n",
        "\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in greeting_inputs:\n",
        "            return random.choice(greeting_responses)\n",
        "\n",
        "# Function to generate response\n",
        "def response(user_response):\n",
        "    user_response = user_response.lower()\n",
        "    sentence_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=Normalize, stop_words=stopwords.words('english'))\n",
        "    tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx = vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if req_tfidf == 0:\n",
        "        return \"I am sorry! I don't understand you.\"\n",
        "    else:\n",
        "        return sentence_tokens[idx]\n",
        "\n",
        "# Chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Chatbot: Hi! I'm a chatbot. How can I help you today?\")\n",
        "    while True:\n",
        "        user_response = input(\"You: \")\n",
        "        if user_response.lower() in ['bye', 'exit', 'quit']:\n",
        "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
        "            break\n",
        "        elif greeting(user_response) is not None:\n",
        "            print(f\"Chatbot: {greeting(user_response)}\")\n",
        "        else:\n",
        "            print(f\"Chatbot: {response(user_response)}\")\n",
        "            sentence_tokens.remove(user_response)\n",
        "\n",
        "# Start the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "oLobX6n1--9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}